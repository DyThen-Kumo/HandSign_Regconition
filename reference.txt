[1] Diane Brentari. A Prosodic Model of Sign Language Phonology. MIT Press, 1998.
[2] Navneet Dalal and Bill Triggs. “Histograms of oriented gradients for human detection”. inProceedings of
the IEEE Conference on Computer Vision and Pattern Recognition: IEEE. 2005, pages 886–893.
[3] Alexey Dosovitskiy andothers. “An Image is Worth 16x16 Words: Transformers for Image Recognition
at Scale”. inInternational Conference on Learning Representations (ICLR): 2021. url: https://arxiv.
org/abs/2010.11929.
[4] Grassknoted. ASL Alphabet. https : / / www . kaggle . com / datasets / grassknoted / asl - alphabet.
Accessed: 2025-06-13. 2017.
[5] Kaiming He andothers. “Deep Residual Learning for Image Recognition”. in2016 IEEE Conference on
Computer Vision and Pattern Recognition (CVPR): 2016, pages 770–778. doi: 10.1109/CVPR.2016.90.
[6] Andrew Howard andothers. “Searching for MobileNetV3”. inarXiv preprint arXiv:1905.02244 : (2019).
url: https://arxiv.org/abs/1905.02244.
[7] Andrew G. Howard andothers. “MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
Applications”. inarXiv preprint arXiv:1704.04861 : 2017. url: https://arxiv.org/abs/1704.04861.
[8] Jie Hu, Li Shen and Gang Sun. “Squeeze-and-Excitation Networks”. inProceedings of the IEEE Conference
on Computer Vision and Pattern Recognition (CVPR): 2018, pages 7132–7141.
[9] Alex Krizhevsky, Ilya Sutskever and Geoffrey E Hinton. “ImageNet classification with deep convolutional
neural networks”. inAdvances in Neural Information Processing Systems : volume 25. 2012.
[10] Yann LeCun andothers. “Gradient-based learning applied to document recognition”. inProceedings of
the IEEE: 86.11 (1998), pages 2278–2324.
[11] David G Lowe. “Distinctive image features from scale-invariant keypoints”. inInternational Journal of
Computer Vision: volume 60. 2. 2004, pages 91–110.
[12] National Association of the Deaf. What is American Sign Language? Truy cập ngày 10 tháng 6 năm 2025.
2022. url: https://www.nad.org/resources/american-sign-language/what-is-american-signlanguage/.
[13] David M. W. Powers. “Evaluation: from precision, recall and F-measure to ROC, informedness, markedness
and correlation”. inJournal of Machine Learning Technologies: 2.1 (2011), pages 37–63.
[14] Danfeng Qin andothers. “MobileNetV4: Universal Models for the Mobile Ecosystem”. inarXiv preprint
arXiv:2404.10518 : (2024). v2, submitted Apr 16 2024, updated Sep 29 2024. url: https://arxiv.org/
abs/2404.10518.
[15] Mark Sandler andothers. “MobileNetV2: Inverted Residuals and Linear Bottlenecks”. inProceedings of
the IEEE Conference on Computer Vision and Pattern Recognition (CVPR): 2018, pages 4510–4520.
url: https://openaccess.thecvf.com/content_cvpr_2018/html/Sandler_MobileNetV2_Inverted_
Residuals_CVPR_2018_paper.html.
[16] Karen Simonyan and Andrew Zisserman. “Very deep convolutional networks for large-scale image recognition”.
inInternational Conference on Learning Representations: 2015.
[17] William C Stokoe. Sign Language Structure: An Outline of the Visual Communication Systems of the
American Deaf. Department of Anthropology and Linguistics, University of Buffalo, 1960.
[18] Mingxing Tan and Quoc V. Le. “EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks”.
inProceedings of the 36th International Conference on Machine Learning (ICML): byeditorKamalika
Chaudhuri and Ruslan Salakhutdinov. volume 97. Proceedings of Machine Learning Research. PMLR,
june 2019, pages 6105–6114. url: https://proceedings.mlr.press/v97/tan19a.html.
[19] Clayton Valli andothers. Linguistics of American Sign Language: An Introduction. Gallaudet University
Press, 2000.
[20] Ashish Vaswani andothers. “Attention Is All You Need”. inAdvances in Neural Information Processing
Systems (NeurIPS): volume 30. 2017. url: https://papers.nips.cc/paper_files/paper/2017/
hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html.